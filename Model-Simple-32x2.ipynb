{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22d218f-4c47-4970-ba11-b62d2d62bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb9b2a62-73b4-4b02-a0af-f948873832ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df with 3980025 rows\n"
     ]
    }
   ],
   "source": [
    "# load in out presaved data\n",
    "df = pd.read_csv(\"black-scholes.csv\", index_col = False)\n",
    "print(\"Loaded df with\",len(df),\"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3746ea45-b123-42d6-83f9-6f0b7d714c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to do a bit of tidying up here for some reason\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.drop(df.columns[0],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532368c6-f030-434b-94bd-b114f95ba6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spot</th>\n",
       "      <th>strike</th>\n",
       "      <th>rate</th>\n",
       "      <th>time</th>\n",
       "      <th>vol</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.063078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.126151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.189217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.252271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.315309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980020</th>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>131.724846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980021</th>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>132.415126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980022</th>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.35</td>\n",
       "      <td>133.561491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980023</th>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>135.125467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980024</th>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>137.031947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980025 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         spot  strike  rate  time   vol       price\n",
       "0          10      10  0.00   0.1  0.05    0.063078\n",
       "1          10      10  0.00   0.1  0.10    0.126151\n",
       "2          10      10  0.00   0.1  0.15    0.189217\n",
       "3          10      10  0.00   0.1  0.20    0.252271\n",
       "4          10      10  0.00   0.1  0.25    0.315309\n",
       "...       ...     ...   ...   ...   ...         ...\n",
       "3980020   190     190  0.24   4.9  0.25  131.724846\n",
       "3980021   190     190  0.24   4.9  0.30  132.415126\n",
       "3980022   190     190  0.24   4.9  0.35  133.561491\n",
       "3980023   190     190  0.24   4.9  0.40  135.125467\n",
       "3980024   190     190  0.24   4.9  0.45  137.031947\n",
       "\n",
       "[3980025 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4523d327-cb2f-464f-adcb-aecad8133992",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(df['price'].values).to(torch.float32)\n",
    "features = torch.tensor(df.drop('price', axis = 1).values).to(torch.float32)\n",
    "\n",
    "# normalize features a bit to remove scaling on asset price mostly\n",
    "# abfix could be done at build time\n",
    "features_norm = features * torch.tensor([1/200, 1/200,1,1/5,1])\n",
    "\n",
    "# divide price by spot to give something thats a bit more regular (%age of notional)\n",
    "target_norm = target / features[:,0]\n",
    "\n",
    "data_set = data_utils.TensorDataset(features_norm, target_norm)\n",
    "train, val, test  = torch.utils.data.random_split(data_set, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader = data_utils.DataLoader(train, batch_size=4, shuffle=True)\n",
    "validation_loader = data_utils.DataLoader(val, batch_size = 4, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8355db56-c9b6-4769-bbc9-3a618cc5c6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 796006 rows\n",
      "features 3980025 3980025\n",
      "target 3980025 3980025\n"
     ]
    }
   ],
   "source": [
    "test_loader = data_utils.DataLoader(test, batch_size = 1, shuffle = True)\n",
    "\n",
    "print(\"Training set has\",len(train_loader),\"rows\")\n",
    "print(\"features\",len(features),len(features_norm))\n",
    "print(\"target\",len(target), len(target_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35747eb9-45da-4e5d-9489-09370ce9efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataiter = iter(train)\n",
    "#feature, price = next(dataiter)\n",
    "#print(feature)\n",
    "#print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e40376f-7208-443f-9a59-78ebbe878cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs_pricer: total params: 2337\n"
     ]
    }
   ],
   "source": [
    "# define a model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super(Net, self).__init__()\n",
    "        if name:\n",
    "            self.name = name\n",
    "\n",
    "        input_nodes = 5\n",
    "        hidden_layer_nodes = 32\n",
    "        output_nodes = 1\n",
    "        self.fc1 = nn.Linear(input_nodes, hidden_layer_nodes)\n",
    "        self.fc2 = nn.Linear(hidden_layer_nodes, hidden_layer_nodes)\n",
    "        self.fc3 = nn.Linear(hidden_layer_nodes, hidden_layer_nodes)\n",
    "        self.fc4 = nn.Linear(hidden_layer_nodes, output_nodes)\n",
    "        \n",
    "        # compute the total number of parameters\n",
    "        total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(self.name + ': total params:', total_params)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net(name='bs_pricer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06a18092-bbf3-47e0-b48d-07f824970e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\CLEAN\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# lets train the model\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.MSELoss()\n",
    "#criterion = lambda y_pred,y : torch.mean((y_pred - y) ** 2)\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36029700-7d68-490e-8d47-ecbc8851767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 100000 == 99999:\n",
    "            last_loss = running_loss / 100000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "#            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e845b1a1-cf86-4982-8e2f-1ca31b63055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 100000 loss: 0.004777037981602416\n",
      "  batch 200000 loss: 0.0008237914394252596\n",
      "  batch 300000 loss: 0.0006179377751449581\n",
      "  batch 400000 loss: 0.0005059094917071598\n",
      "  batch 500000 loss: 0.00044195710534388816\n",
      "  batch 600000 loss: 0.00039244722047261063\n",
      "  batch 700000 loss: 0.00035141954455283127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\CLEAN\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.00035141954455283127 valid 0.00030334858456626534\n",
      "EPOCH 2:\n",
      "  batch 100000 loss: 0.00029138407854437164\n",
      "  batch 200000 loss: 0.0002723527919736213\n",
      "  batch 300000 loss: 0.00025931411942784675\n",
      "  batch 400000 loss: 0.00024568636165161876\n",
      "  batch 500000 loss: 0.00023643012834156395\n",
      "  batch 600000 loss: 0.0002237081465545731\n",
      "  batch 700000 loss: 0.00021546315625397\n",
      "LOSS train 0.00021546315625397 valid 0.00018858157272916287\n",
      "EPOCH 3:\n",
      "  batch 100000 loss: 0.0002018441293109362\n",
      "  batch 200000 loss: 0.00019575269529270258\n",
      "  batch 300000 loss: 0.00018979877643752872\n",
      "  batch 400000 loss: 0.00018529852934377487\n",
      "  batch 500000 loss: 0.00017701130617561516\n",
      "  batch 600000 loss: 0.0001711914210734613\n",
      "  batch 700000 loss: 0.00016726047340364302\n",
      "LOSS train 0.00016726047340364302 valid 0.00016826781211420894\n",
      "EPOCH 4:\n",
      "  batch 100000 loss: 0.00015631404554476263\n",
      "  batch 200000 loss: 0.0001515017679297982\n",
      "  batch 300000 loss: 0.00014710865465555857\n",
      "  batch 400000 loss: 0.00014492950402610177\n",
      "  batch 500000 loss: 0.00014100159926114827\n",
      "  batch 600000 loss: 0.00013554419130049\n",
      "  batch 700000 loss: 0.00013413017488242063\n",
      "LOSS train 0.00013413017488242063 valid 0.0001583177800057456\n",
      "EPOCH 5:\n",
      "  batch 100000 loss: 0.00012681786830344934\n",
      "  batch 200000 loss: 0.00012346802384934392\n",
      "  batch 300000 loss: 0.00012203362470511187\n",
      "  batch 400000 loss: 0.00011821108377856263\n",
      "  batch 500000 loss: 0.00011530653256619135\n",
      "  batch 600000 loss: 0.00011312594597605525\n",
      "  batch 700000 loss: 0.00011054298348754692\n",
      "LOSS train 0.00011054298348754692 valid 0.00012707363930530846\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "writer = None\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs.squeeze(), vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss           \n",
    "        model_path = 'model_32_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1ee696-fa6d-4988-b603-573d45f03f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d496d91a-2dcb-4da1-9e86-76e2df94f902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 0.3000, 0.1700, 0.8600, 0.0500]])\n",
      "tensor([0.2779])\n",
      "tensor([[0.2672]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.7000, 0.7500, 0.1500, 0.1000, 0.2000]])\n",
      "tensor([0.0592])\n",
      "tensor([[0.0617]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.9000, 0.9500, 0.0500, 0.0400, 0.3000]])\n",
      "tensor([0.0351])\n",
      "tensor([[0.0280]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.6500, 0.5000, 0.0500, 0.0800, 0.2000]])\n",
      "tensor([0.2465])\n",
      "tensor([[0.2507]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.4500, 0.3500, 0.0500, 0.8200, 0.4500]])\n",
      "tensor([0.5023])\n",
      "tensor([[0.5020]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.3000, 0.7000, 0.0700, 0.0600, 0.2000]])\n",
      "tensor([4.8694e-16])\n",
      "tensor([[0.0024]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.8000, 0.7500, 0.2400, 0.4600, 0.1500]])\n",
      "tensor([0.4604])\n",
      "tensor([[0.4619]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.6000, 0.3000, 0.2400, 0.0200, 0.0500]])\n",
      "tensor([0.5119])\n",
      "tensor([[0.5263]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.5500, 0.7500, 0.2100, 0.9800, 0.2000]])\n",
      "tensor([0.5194])\n",
      "tensor([[0.5265]], grad_fn=<AddmmBackward0>)\n",
      "----------\n",
      "tensor([[0.8500, 0.6000, 0.2200, 0.3000, 0.2500]])\n",
      "tensor([0.4935])\n",
      "tensor([[0.5032]], grad_fn=<AddmmBackward0>)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    f,l = next(test_iter)\n",
    "    print(f)\n",
    "    print(l)\n",
    "    price = model(f)\n",
    "    print(price)\n",
    "\n",
    "\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1fadfca-6356-4d77-8677-82ba6f9e6dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS TEST 0.00011054298348754692 valid 3.161091808578931e-05\n"
     ]
    }
   ],
   "source": [
    "# now compare on all test data\n",
    "\n",
    "# Set the model to evaluation mode, disabling dropout and using population\n",
    "# statistics for batch normalization.\n",
    "model.eval()\n",
    "\n",
    "running_tloss=0.0\n",
    "\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "with torch.no_grad():\n",
    "    for i, vdata in enumerate(test_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        tloss = loss_fn(voutputs.squeeze(), vlabels)\n",
    "        running_tloss += tloss\n",
    "\n",
    "avg_tloss = running_tloss / (i + 1)\n",
    "print('LOSS TEST {} valid {}'.format(avg_loss, avg_tloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f21af-d668-44d0-8a07-0ba4af2be58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
